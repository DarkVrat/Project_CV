{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea70bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорты\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a8752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка изображений из папки\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ad8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение данных определённого размера для тренировки\n",
    "def create_training_data(target_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    persons = os.listdir('data')\n",
    "    num_classes = len(persons)\n",
    "\n",
    "    for person_index, person in enumerate(persons):\n",
    "        folder_path = os.path.join('data', person)\n",
    "        person_images = load_images_from_folder(folder_path)\n",
    "        resized_images = [cv2.resize(img, target_size) for img in person_images]\n",
    "        images.extend(resized_images)\n",
    "        labels.extend([person_index] * len(resized_images))\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b43988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_pairs):\n",
    "    preprocessed_pairs = []\n",
    "    for pair in data_pairs:\n",
    "        preprocessed_pair = []\n",
    "        for image in pair:\n",
    "            image_array = np.array(image)\n",
    "            image_array = image_array / 255.0\n",
    "            preprocessed_pair.append(image_array)\n",
    "        preprocessed_pairs.append(preprocessed_pair)\n",
    "    return np.array(preprocessed_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d42994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сама модель нейронки, на вход 150х150х3 картинка, на выходе определяет принодлежность к классу из num_classes\n",
    "def create_model():\n",
    "    input_shape = (150, 150, 3)\n",
    "    \n",
    "    # Модель для первого изображения\n",
    "    input1 = Input(shape=input_shape)\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu')(input1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Conv2D(128, (3, 3), activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(128, activation='relu')(x1)\n",
    "    \n",
    "    # Модель для второго изображения\n",
    "    input2 = Input(shape=input_shape)\n",
    "    x2 = Conv2D(64, (3, 3), activation='relu')(input2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Conv2D(128, (3, 3), activation='relu')(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(128, activation='relu')(x2)\n",
    "    \n",
    "    # Объединение двух ветвей\n",
    "    merged = tf.keras.layers.concatenate([x1, x2])\n",
    "    \n",
    "    x = Dense(128, activation='relu')(merged)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (150, 150)\n",
    "images, labels, num_classes = create_training_data(target_size)\n",
    "\n",
    "image_pairs = []\n",
    "label_pairs = []\n",
    "\n",
    "count=0\n",
    "for i in range(len(images)):\n",
    "    for j in range(i , len(images)):\n",
    "        image_pairs.append([images[i], images[j]])\n",
    "        if labels[i] == labels[j]:\n",
    "            label_pairs.append(True)\n",
    "        else:\n",
    "            label_pairs.append(False)\n",
    "\n",
    "image_pairs = np.array(image_pairs)\n",
    "label_pairs = np.array(label_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce2055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pairs, x_val_pairs, y_train_pairs, y_val_pairs = train_test_split(image_pairs, label_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_pairs = np.array(y_train_pairs).astype(int)\n",
    "y_val_pairs = np.array(y_val_pairs).astype(int)\n",
    "\n",
    "x_train_pairs = preprocess_data(x_train_pairs)\n",
    "x_val_pairs = preprocess_data(x_val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96e1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "085a2373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbest_val_accuracy = 0.0\\n\\nfor run in range(20):\\n    print(f\"Запуск {run}\")\\n    model = create_model()\\n    model.compile(loss=\\'binary_crossentropy\\', optimizer=optimizer, metrics=[\\'accuracy\\'], run_eagerly=True)\\n    checkpoint = ModelCheckpoint(\\'retrained.h5\\', monitor=\\'val_accuracy\\', verbose=1, save_best_only=True, mode=\\'max\\')\\n    \\n    history = model.fit(\\n        [x_train_pairs[:, 0], x_train_pairs[:, 1]],\\n        y_train_pairs,\\n        batch_size=batch_size,\\n        epochs=epochs,  \\n        shuffle=True,\\n        validation_data=([x_val_pairs[:, 0], x_val_pairs[:, 1]], y_val_pairs),\\n        callbacks=[checkpoint]\\n    )\\n    \\n    val_accuracy = max(history.history[\\'val_accuracy\\'])\\n    if val_accuracy > best_val_accuracy:\\n        best_val_accuracy = val_accuracy\\n        model.load_weights(\\'retrained.h5\\')\\n        model.save(\\'best_retrained.h5\\')\\n    \\n    print(\"Текущая точность на валидации:\", val_accuracy)\\n    print(\"Лучшая точность на валидации:\", best_val_accuracy)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучение\n",
    "\"\"\"\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for run in range(20):\n",
    "    print(f\"Запуск {run}\")\n",
    "    model = create_model()\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'], run_eagerly=True)\n",
    "    checkpoint = ModelCheckpoint('retrained.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    history = model.fit(\n",
    "        [x_train_pairs[:, 0], x_train_pairs[:, 1]],\n",
    "        y_train_pairs,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,  \n",
    "        shuffle=True,\n",
    "        validation_data=([x_val_pairs[:, 0], x_val_pairs[:, 1]], y_val_pairs),\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "    \n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model.load_weights('retrained.h5')\n",
    "        model.save('best_retrained.h5')\n",
    "    \n",
    "    print(\"Текущая точность на валидации:\", val_accuracy)\n",
    "    print(\"Лучшая точность на валидации:\", best_val_accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86cb0c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 19s 604ms/step - loss: 0.0841 - accuracy: 0.9931\n",
      "Текущий accuracy:  0.9930692911148071\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'], run_eagerly=True)\n",
    "model.load_weights('model/best_retrained.h5')\n",
    "\n",
    "epochs=131\n",
    "\n",
    "best_val_accuracy = model.evaluate([x_val_pairs[:, 0], x_val_pairs[:, 1]], y_val_pairs)[1]\n",
    "print('Текущий accuracy: ', best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8143d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while True:\\n    checkpoint = ModelCheckpoint(\\'retrained.h5\\', monitor=\\'val_accuracy\\', verbose=1, save_best_only=True, mode=\\'max\\')\\n    \\n    history = model.fit(\\n        [x_train_pairs[:, 0], x_train_pairs[:, 1]],\\n        y_train_pairs,\\n        batch_size=batch_size,\\n        epochs=epochs + 10,\\n        shuffle=True,\\n        validation_data=([x_val_pairs[:, 0], x_val_pairs[:, 1]], y_val_pairs),\\n        callbacks=[checkpoint],\\n        initial_epoch=epochs\\n    )\\n\\n    val_accuracy = max(history.history[\\'val_accuracy\\'])\\n    print(\"Точность на валидации после новой эпох:\", val_accuracy)\\n\\n    if val_accuracy > best_val_accuracy:\\n        best_val_accuracy = val_accuracy\\n        model.load_weights(\\'retrained.h5\\')\\n        model.save_weights(\\'model/best_retrained.h5\\')\\n        epochs += 10\\n        print(\"Новые веса сохранены\")\\n\\n    else:\\n        model.load_weights(\\'model/best_retrained.h5\\')\\n        print(\"Загружены предыдущие лучшие веса\")\\n        \\n    if val_accuracy >= 0.999:\\n        break'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"while True:\n",
    "    checkpoint = ModelCheckpoint('retrained.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    history = model.fit(\n",
    "        [x_train_pairs[:, 0], x_train_pairs[:, 1]],\n",
    "        y_train_pairs,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs + 10,\n",
    "        shuffle=True,\n",
    "        validation_data=([x_val_pairs[:, 0], x_val_pairs[:, 1]], y_val_pairs),\n",
    "        callbacks=[checkpoint],\n",
    "        initial_epoch=epochs\n",
    "    )\n",
    "\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(\"Точность на валидации после новой эпох:\", val_accuracy)\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model.load_weights('retrained.h5')\n",
    "        model.save_weights('model/best_retrained.h5')\n",
    "        epochs += 10\n",
    "        print(\"Новые веса сохранены\")\n",
    "\n",
    "    else:\n",
    "        model.load_weights('model/best_retrained.h5')\n",
    "        print(\"Загружены предыдущие лучшие веса\")\n",
    "        \n",
    "    if val_accuracy >= 0.999:\n",
    "        break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfdabd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model_v0.993069.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434ce9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pair(image_path1, image_path2, model):\n",
    "    image1 = load_and_preprocess_image(image_path1)\n",
    "    image2 = load_and_preprocess_image(image_path2)\n",
    "    prediction = model.predict([[image1], [image2]])\n",
    "    if prediction > 0.5:\n",
    "        print(\"Да\")\n",
    "    else:\n",
    "        print(\"Нет\")\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (150, 150))\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d031883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Да\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Да\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Нет\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'], run_eagerly=True)\n",
    "model.load_weights('model/best_retrained.h5')\n",
    "\n",
    "predict_pair('test/test_ (1).jpg','test/test_ (1).jpg', model)#Да\n",
    "predict_pair('test/test_ (1).jpg','test/test_ (2).jpg', model)#Да\n",
    "predict_pair('test/test_ (1).jpg','test/test_ (3).jpg', model)#Нет\n",
    "predict_pair('test/test_ (1).jpg','test/test_ (4).jpg', model)#Нет\n",
    "predict_pair('test/test_ (1).jpg','test/test_ (5).jpg', model)#Нет\n",
    "predict_pair('test/test_ (1).jpg','test/test_ (6).jpg', model)#Нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcde2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "Да\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Нет\n"
     ]
    }
   ],
   "source": [
    "predict_pair('test/test_ (2).jpg','test/test_ (2).jpg', model)#Да\n",
    "predict_pair('test/test_ (2).jpg','test/test_ (3).jpg', model)#Нет\n",
    "predict_pair('test/test_ (2).jpg','test/test_ (4).jpg', model)#Нет\n",
    "predict_pair('test/test_ (2).jpg','test/test_ (5).jpg', model)#Нет\n",
    "predict_pair('test/test_ (2).jpg','test/test_ (6).jpg', model)#Нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3799948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "Да\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Да\n"
     ]
    }
   ],
   "source": [
    "predict_pair('test/test_ (3).jpg','test/test_ (3).jpg', model)#Да\n",
    "predict_pair('test/test_ (3).jpg','test/test_ (4).jpg', model)#Нет\n",
    "predict_pair('test/test_ (3).jpg','test/test_ (5).jpg', model)#Нет\n",
    "predict_pair('test/test_ (3).jpg','test/test_ (6).jpg', model)#Нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bdca598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "Да\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Нет\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Да\n"
     ]
    }
   ],
   "source": [
    "predict_pair('test/test_ (4).jpg','test/test_ (4).jpg', model)#Да\n",
    "predict_pair('test/test_ (4).jpg','test/test_ (5).jpg', model)#Нет\n",
    "predict_pair('test/test_ (4).jpg','test/test_ (6).jpg', model)#Нет\n",
    "predict_pair('test/test_ (5).jpg','test/test_ (5).jpg', model)#Да\n",
    "predict_pair('test/test_ (5).jpg','test/test_ (6).jpg', model)#Да\n",
    "predict_pair('test/test_ (6).jpg','test/test_ (6).jpg', model)#Да"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b97e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
